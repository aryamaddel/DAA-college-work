{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca55656",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Sorting Algorithm Analysis\n",
    "\n",
    "This notebook performs sorting algorithm analysis using GPU acceleration with CuPy for better performance on Google Colab.\n",
    "\n",
    "**Requirements:** \n",
    "- GPU runtime in Google Colab\n",
    "- CuPy for GPU-accelerated array operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for GPU acceleration\n",
    "!pip install cupy-cuda12x matplotlib seaborn numpy\n",
    "\n",
    "# Check if GPU is available\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f26592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CuPy version: {cp.__version__}\")\n",
    "print(f\"GPU available: {cp.cuda.is_available()}\")\n",
    "if cp.cuda.is_available():\n",
    "    print(f\"GPU name: {cp.cuda.Device().name.decode()}\")\n",
    "    print(f\"GPU memory: {cp.cuda.Device().mem_info[1] / 1e9:.1f} GB\")\n",
    "\n",
    "# Test sizes - larger sizes for GPU testing\n",
    "sizes = [1000, 5000, 10000, 25000, 50000, 100000, 250000, 500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_sort_cpu(sort_func, arr, runs=5):\n",
    "    \"\"\"Time a CPU sorting function\"\"\"\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        test_arr = arr.copy()\n",
    "        start = time.perf_counter()\n",
    "        sort_func(test_arr)\n",
    "        end = time.perf_counter()\n",
    "        times.append(end - start)\n",
    "    return np.mean(times)\n",
    "\n",
    "def time_sort_gpu(sort_func, arr, runs=5):\n",
    "    \"\"\"Time a GPU sorting function\"\"\"\n",
    "    times = []\n",
    "    gpu_arr = cp.array(arr)\n",
    "    \n",
    "    for _ in range(runs):\n",
    "        test_arr = gpu_arr.copy()\n",
    "        cp.cuda.Stream.null.synchronize()  # Ensure GPU is ready\n",
    "        start = time.perf_counter()\n",
    "        sort_func(test_arr)\n",
    "        cp.cuda.Stream.null.synchronize()  # Wait for completion\n",
    "        end = time.perf_counter()\n",
    "        times.append(end - start)\n",
    "    \n",
    "    return np.mean(times)\n",
    "\n",
    "def generate_test_data(size, data_type='random'):\n",
    "    \"\"\"Generate test data of different types\"\"\"\n",
    "    if data_type == 'random':\n",
    "        return np.random.randint(0, 100000, size)\n",
    "    elif data_type == 'sorted':\n",
    "        return np.arange(size)\n",
    "    elif data_type == 'reverse':\n",
    "        return np.arange(size, 0, -1)\n",
    "    elif data_type == 'nearly_sorted':\n",
    "        arr = np.arange(size)\n",
    "        # Swap 5% of elements randomly\n",
    "        swaps = size // 20\n",
    "        for _ in range(swaps):\n",
    "            i, j = np.random.randint(0, size, 2)\n",
    "            arr[i], arr[j] = arr[j], arr[i]\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334dd58f",
   "metadata": {},
   "source": [
    "## CPU Sorting Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62571577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort_cpu(arr):\n",
    "    \"\"\"Optimized Bubble Sort with early termination\"\"\"\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        swapped = False\n",
    "        for j in range(0, n - i - 1):\n",
    "            if arr[j] > arr[j + 1]:\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "                swapped = True\n",
    "        if not swapped:\n",
    "            break\n",
    "\n",
    "def insertion_sort_cpu(arr):\n",
    "    \"\"\"Optimized Insertion Sort\"\"\"\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]\n",
    "        j = i - 1\n",
    "        while j >= 0 and arr[j] > key:\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = key\n",
    "\n",
    "def quick_sort_cpu(arr):\n",
    "    \"\"\"Optimized Quick Sort with random pivot\"\"\"\n",
    "    def partition(arr, low, high):\n",
    "        # Random pivot selection\n",
    "        random_idx = np.random.randint(low, high + 1)\n",
    "        arr[random_idx], arr[high] = arr[high], arr[random_idx]\n",
    "        \n",
    "        pivot = arr[high]\n",
    "        i = low - 1\n",
    "        for j in range(low, high):\n",
    "            if arr[j] <= pivot:\n",
    "                i += 1\n",
    "                arr[i], arr[j] = arr[j], arr[i]\n",
    "        arr[i + 1], arr[high] = arr[high], arr[i + 1]\n",
    "        return i + 1\n",
    "\n",
    "    def quick_sort_helper(arr, low, high):\n",
    "        if low < high:\n",
    "            pi = partition(arr, low, high)\n",
    "            quick_sort_helper(arr, low, pi - 1)\n",
    "            quick_sort_helper(arr, pi + 1, high)\n",
    "\n",
    "    quick_sort_helper(arr, 0, len(arr) - 1)\n",
    "\n",
    "def merge_sort_cpu(arr):\n",
    "    \"\"\"Optimized Merge Sort\"\"\"\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    \n",
    "    mid = len(arr) // 2\n",
    "    left = merge_sort_cpu(arr[:mid])\n",
    "    right = merge_sort_cpu(arr[mid:])\n",
    "    \n",
    "    # Merge\n",
    "    result = []\n",
    "    i = j = 0\n",
    "    while i < len(left) and j < len(right):\n",
    "        if left[i] <= right[j]:\n",
    "            result.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(right[j])\n",
    "            j += 1\n",
    "    \n",
    "    result.extend(left[i:])\n",
    "    result.extend(right[j:])\n",
    "    \n",
    "    # Copy back to original array\n",
    "    for i, val in enumerate(result):\n",
    "        arr[i] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280f704",
   "metadata": {},
   "source": [
    "## GPU-Accelerated Sorting Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radix_sort_gpu(arr):\n",
    "    \"\"\"GPU-accelerated Radix Sort using CuPy\"\"\"\n",
    "    if len(arr) == 0:\n",
    "        return\n",
    "    \n",
    "    max_val = cp.max(arr)\n",
    "    exp = 1\n",
    "    \n",
    "    while max_val // exp > 0:\n",
    "        # Count sort based on digit represented by exp\n",
    "        n = len(arr)\n",
    "        output = cp.zeros(n, dtype=arr.dtype)\n",
    "        count = cp.zeros(10, dtype=cp.int32)\n",
    "        \n",
    "        # Count occurrences of each digit\n",
    "        digits = (arr // exp) % 10\n",
    "        for i in range(10):\n",
    "            count[i] = cp.sum(digits == i)\n",
    "        \n",
    "        # Cumulative count\n",
    "        for i in range(1, 10):\n",
    "            count[i] += count[i - 1]\n",
    "        \n",
    "        # Build output array\n",
    "        for i in range(n - 1, -1, -1):\n",
    "            digit = (arr[i] // exp) % 10\n",
    "            count[digit] -= 1\n",
    "            output[count[digit]] = arr[i]\n",
    "        \n",
    "        # Copy output to arr\n",
    "        arr[:] = output[:]\n",
    "        exp *= 10\n",
    "\n",
    "def gpu_built_in_sort(arr):\n",
    "    \"\"\"Use CuPy's built-in GPU sort\"\"\"\n",
    "    arr[:] = cp.sort(arr)\n",
    "\n",
    "def bitonic_sort_gpu(arr):\n",
    "    \"\"\"GPU Bitonic Sort (works best with power of 2 sizes)\"\"\"\n",
    "    n = len(arr)\n",
    "    \n",
    "    # Pad to next power of 2 if necessary\n",
    "    next_pow2 = 1\n",
    "    while next_pow2 < n:\n",
    "        next_pow2 *= 2\n",
    "    \n",
    "    if next_pow2 > n:\n",
    "        padded = cp.full(next_pow2, cp.max(arr) + 1, dtype=arr.dtype)\n",
    "        padded[:n] = arr\n",
    "        arr_to_sort = padded\n",
    "    else:\n",
    "        arr_to_sort = arr\n",
    "    \n",
    "    def bitonic_merge(arr, start, cnt, up):\n",
    "        if cnt > 1:\n",
    "            k = cnt // 2\n",
    "            for i in range(start, start + k):\n",
    "                if (arr[i] > arr[i + k]) == up:\n",
    "                    arr[i], arr[i + k] = arr[i + k], arr[i]\n",
    "            bitonic_merge(arr, start, k, up)\n",
    "            bitonic_merge(arr, start + k, k, up)\n",
    "    \n",
    "    def bitonic_sort_recursive(arr, start, cnt, up):\n",
    "        if cnt > 1:\n",
    "            k = cnt // 2\n",
    "            bitonic_sort_recursive(arr, start, k, True)\n",
    "            bitonic_sort_recursive(arr, start + k, k, False)\n",
    "            bitonic_merge(arr, start, cnt, up)\n",
    "    \n",
    "    bitonic_sort_recursive(arr_to_sort, 0, len(arr_to_sort), True)\n",
    "    \n",
    "    if next_pow2 > n:\n",
    "        arr[:] = arr_to_sort[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b59637",
   "metadata": {},
   "source": [
    "## Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05671847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different data types\n",
    "data_types = ['random', 'sorted', 'reverse', 'nearly_sorted']\n",
    "\n",
    "# CPU algorithms\n",
    "cpu_algorithms = {\n",
    "    'Bubble Sort (CPU)': bubble_sort_cpu,\n",
    "    'Insertion Sort (CPU)': insertion_sort_cpu,\n",
    "    'Quick Sort (CPU)': quick_sort_cpu,\n",
    "    'Merge Sort (CPU)': merge_sort_cpu,\n",
    "    'NumPy Sort (CPU)': lambda arr: arr.sort()\n",
    "}\n",
    "\n",
    "# GPU algorithms (if GPU is available)\n",
    "gpu_algorithms = {}\n",
    "if cp.cuda.is_available():\n",
    "    gpu_algorithms = {\n",
    "        'Radix Sort (GPU)': radix_sort_gpu,\n",
    "        'CuPy Sort (GPU)': gpu_built_in_sort,\n",
    "        'Bitonic Sort (GPU)': bitonic_sort_gpu\n",
    "    }\n",
    "\n",
    "print(f\"Testing {len(cpu_algorithms)} CPU algorithms and {len(gpu_algorithms)} GPU algorithms\")\n",
    "print(f\"Data types: {data_types}\")\n",
    "print(f\"Array sizes: {sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f53611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive performance tests\n",
    "results = {}\n",
    "\n",
    "for data_type in ['random']:  # Focus on random data for main analysis\n",
    "    print(f\"\\nTesting with {data_type} data...\")\n",
    "    results[data_type] = {}\n",
    "    \n",
    "    for alg_name, alg_func in {**cpu_algorithms, **gpu_algorithms}.items():\n",
    "        if 'Bubble' in alg_name and max(sizes) > 50000:\n",
    "            # Skip bubble sort for very large sizes\n",
    "            test_sizes = [s for s in sizes if s <= 50000]\n",
    "        else:\n",
    "            test_sizes = sizes\n",
    "            \n",
    "        results[data_type][alg_name] = []\n",
    "        print(f\"  Testing {alg_name}...\")\n",
    "        \n",
    "        for size in test_sizes:\n",
    "            arr = generate_test_data(size, data_type)\n",
    "            \n",
    "            try:\n",
    "                if 'GPU' in alg_name:\n",
    "                    avg_time = time_sort_gpu(alg_func, arr)\n",
    "                else:\n",
    "                    avg_time = time_sort_cpu(alg_func, arr)\n",
    "                \n",
    "                results[data_type][alg_name].append(avg_time)\n",
    "                print(f\"    Size {size:>6}: {avg_time:.6f}s\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Size {size:>6}: ERROR - {e}\")\n",
    "                results[data_type][alg_name].append(float('inf'))\n",
    "        \n",
    "        # Pad with inf for skipped sizes\n",
    "        while len(results[data_type][alg_name]) < len(sizes):\n",
    "            results[data_type][alg_name].append(float('inf'))\n",
    "\n",
    "print(\"\\nPerformance testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5640f",
   "metadata": {},
   "source": [
    "## Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8115cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('GPU-Accelerated Sorting Algorithm Performance Analysis', fontsize=16)\n",
    "\n",
    "data_type = 'random'\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(results[data_type])))\n",
    "\n",
    "# 1. Linear scale comparison\n",
    "ax1 = axes[0, 0]\n",
    "for i, (alg_name, times) in enumerate(results[data_type].items()):\n",
    "    valid_times = [t if t != float('inf') else np.nan for t in times]\n",
    "    valid_sizes = sizes[:len(valid_times)]\n",
    "    ax1.plot(valid_sizes, valid_times, 'o-', label=alg_name, color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax1.set_xlabel('Input Size')\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.set_title('Performance Comparison (Linear Scale)')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Log scale comparison\n",
    "ax2 = axes[0, 1]\n",
    "for i, (alg_name, times) in enumerate(results[data_type].items()):\n",
    "    valid_times = [t if t != float('inf') else np.nan for t in times]\n",
    "    valid_sizes = sizes[:len(valid_times)]\n",
    "    ax2.semilogy(valid_sizes, valid_times, 'o-', label=alg_name, color=colors[i], linewidth=2, markersize=6)\n",
    "\n",
    "ax2.set_xlabel('Input Size')\n",
    "ax2.set_ylabel('Time (seconds) - Log Scale')\n",
    "ax2.set_title('Performance Comparison (Log Scale)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. GPU vs CPU comparison for largest size\n",
    "ax3 = axes[0, 2]\n",
    "gpu_times = []\n",
    "cpu_times = []\n",
    "labels = []\n",
    "\n",
    "for alg_name, times in results[data_type].items():\n",
    "    if times[-1] != float('inf'):\n",
    "        if 'GPU' in alg_name:\n",
    "            gpu_times.append(times[-1])\n",
    "            labels.append(alg_name.replace(' (GPU)', ''))\n",
    "        else:\n",
    "            cpu_times.append(times[-1])\n",
    "\n",
    "x_pos = np.arange(len(labels))\n",
    "if gpu_times and cpu_times:\n",
    "    width = 0.35\n",
    "    bars1 = ax3.bar(x_pos - width/2, cpu_times[:len(gpu_times)], width, label='CPU', alpha=0.8)\n",
    "    bars2 = ax3.bar(x_pos + width/2, gpu_times, width, label='GPU', alpha=0.8)\n",
    "    \n",
    "    ax3.set_xlabel('Algorithm')\n",
    "    ax3.set_ylabel('Time (seconds)')\n",
    "    ax3.set_title(f'GPU vs CPU at Size {sizes[-1]}')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(labels, rotation=45)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Speedup analysis\n",
    "ax4 = axes[1, 0]\n",
    "if cp.cuda.is_available() and 'CuPy Sort (GPU)' in results[data_type] and 'NumPy Sort (CPU)' in results[data_type]:\n",
    "    gpu_times = results[data_type]['CuPy Sort (GPU)']\n",
    "    cpu_times = results[data_type]['NumPy Sort (CPU)']\n",
    "    speedup = [cpu/gpu if gpu != float('inf') and gpu > 0 else 0 for cpu, gpu in zip(cpu_times, gpu_times)]\n",
    "    \n",
    "    ax4.plot(sizes, speedup, 'ro-', linewidth=3, markersize=8)\n",
    "    ax4.set_xlabel('Input Size')\n",
    "    ax4.set_ylabel('Speedup (CPU time / GPU time)')\n",
    "    ax4.set_title('GPU Speedup vs CPU')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.axhline(y=1, color='k', linestyle='--', alpha=0.5, label='No speedup')\n",
    "    ax4.legend()\n",
    "\n",
    "# 5. Memory efficiency (theoretical)\n",
    "ax5 = axes[1, 1]\n",
    "memory_usage = {}\n",
    "for size in sizes:\n",
    "    memory_usage[size] = {\n",
    "        'Quick Sort': size * 8 * np.log2(size),  # O(log n) space\n",
    "        'Merge Sort': size * 8 * 2,  # O(n) space\n",
    "        'Radix Sort': size * 8 * 2,  # O(n) space\n",
    "        'In-place': size * 8  # O(1) additional space\n",
    "    }\n",
    "\n",
    "for alg, color in zip(['Quick Sort', 'Merge Sort', 'Radix Sort', 'In-place'], ['blue', 'green', 'red', 'orange']):\n",
    "    memory_vals = [memory_usage[size][alg] / 1e6 for size in sizes]  # Convert to MB\n",
    "    ax5.plot(sizes, memory_vals, 'o-', label=alg, color=color, linewidth=2)\n",
    "\n",
    "ax5.set_xlabel('Input Size')\n",
    "ax5.set_ylabel('Memory Usage (MB)')\n",
    "ax5.set_title('Theoretical Memory Usage')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Algorithm complexity comparison\n",
    "ax6 = axes[1, 2]\n",
    "n_vals = np.array(sizes)\n",
    "complexities = {\n",
    "    'O(n²)': n_vals**2,\n",
    "    'O(n log n)': n_vals * np.log2(n_vals),\n",
    "    'O(n)': n_vals,\n",
    "    'O(log n)': np.log2(n_vals)\n",
    "}\n",
    "\n",
    "for complexity, values in complexities.items():\n",
    "    normalized_values = values / values[0]  # Normalize to first value\n",
    "    ax6.loglog(sizes, normalized_values, 'o-', label=complexity, linewidth=2)\n",
    "\n",
    "ax6.set_xlabel('Input Size')\n",
    "ax6.set_ylabel('Normalized Operations')\n",
    "ax6.set_title('Time Complexity Comparison')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_type = 'random'\n",
    "print(f\"\\nData Type: {data_type.upper()}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Algorithm':<20} {'Smallest':<12} {'Largest':<12} {'Complexity':<15} {'Type':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "complexity_map = {\n",
    "    'Bubble Sort (CPU)': 'O(n²)',\n",
    "    'Insertion Sort (CPU)': 'O(n²)',\n",
    "    'Quick Sort (CPU)': 'O(n log n)',\n",
    "    'Merge Sort (CPU)': 'O(n log n)',\n",
    "    'NumPy Sort (CPU)': 'O(n log n)',\n",
    "    'Radix Sort (GPU)': 'O(d × n)',\n",
    "    'CuPy Sort (GPU)': 'O(n log n)',\n",
    "    'Bitonic Sort (GPU)': 'O(log²n)'\n",
    "}\n",
    "\n",
    "for alg_name, times in results[data_type].items():\n",
    "    if times[0] != float('inf') and times[-1] != float('inf'):\n",
    "        smallest_time = times[0]\n",
    "        largest_time = times[-1]\n",
    "        complexity = complexity_map.get(alg_name, 'Unknown')\n",
    "        alg_type = 'GPU' if 'GPU' in alg_name else 'CPU'\n",
    "        \n",
    "        print(f\"{alg_name:<20} {smallest_time:<12.6f} {largest_time:<12.6f} {complexity:<15} {alg_type:<8}\")\n",
    "\n",
    "# GPU Speedup Analysis\n",
    "if cp.cuda.is_available():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GPU SPEEDUP ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if 'CuPy Sort (GPU)' in results[data_type] and 'NumPy Sort (CPU)' in results[data_type]:\n",
    "        gpu_times = results[data_type]['CuPy Sort (GPU)']\n",
    "        cpu_times = results[data_type]['NumPy Sort (CPU)']\n",
    "        \n",
    "        print(f\"\\n{'Size':<10} {'CPU Time':<12} {'GPU Time':<12} {'Speedup':<10} {'Efficiency':<12}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for i, size in enumerate(sizes):\n",
    "            if gpu_times[i] != float('inf') and cpu_times[i] != float('inf') and gpu_times[i] > 0:\n",
    "                speedup = cpu_times[i] / gpu_times[i]\n",
    "                efficiency = speedup * 100  # Percentage\n",
    "                print(f\"{size:<10} {cpu_times[i]:<12.6f} {gpu_times[i]:<12.6f} {speedup:<10.2f}x {efficiency:<12.1f}%\")\n",
    "\n",
    "    print(\"\\nNotes:\")\n",
    "    print(\"- Speedup = CPU Time / GPU Time\")\n",
    "    print(\"- Efficiency shows percentage improvement\")\n",
    "    print(\"- GPU performance improves with larger datasets due to parallelization\")\n",
    "    print(\"- Memory transfer overhead affects small dataset performance\")\n",
    "\n",
    "# Best algorithm recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALGORITHM RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nBest algorithms by use case:\")\n",
    "print(\"• Small datasets (< 10,000): NumPy Sort (CPU) or Insertion Sort\")\n",
    "print(\"• Medium datasets (10,000 - 100,000): Quick Sort (CPU) or CuPy Sort (GPU)\")\n",
    "print(\"• Large datasets (> 100,000): CuPy Sort (GPU) or Radix Sort (GPU)\")\n",
    "print(\"• Nearly sorted data: Insertion Sort or optimized Bubble Sort\")\n",
    "print(\"• Memory constrained: Quick Sort (in-place) or Bubble Sort\")\n",
    "print(\"• Parallel processing: GPU-based algorithms (CuPy, Radix)\")\n",
    "\n",
    "print(\"\\nComplexity Summary:\")\n",
    "print(\"• O(n²): Bubble Sort, Insertion Sort - Good for small/nearly sorted data\")\n",
    "print(\"• O(n log n): Quick Sort, Merge Sort, NumPy/CuPy Sort - General purpose\")\n",
    "print(\"• O(d × n): Radix Sort - Excellent for integers with limited range\")\n",
    "print(\"• O(log²n): Bitonic Sort - Highly parallel, good for GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa5d9d",
   "metadata": {},
   "source": [
    "## Additional GPU Performance Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dcd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different data distributions if GPU is available\n",
    "if cp.cuda.is_available():\n",
    "    print(\"Testing GPU algorithms with different data distributions...\\n\")\n",
    "    \n",
    "    test_size = 100000\n",
    "    distributions = {\n",
    "        'Random': np.random.randint(0, 100000, test_size),\n",
    "        'Sorted': np.arange(test_size),\n",
    "        'Reverse Sorted': np.arange(test_size, 0, -1),\n",
    "        'Nearly Sorted': np.concatenate([np.arange(test_size-1000), np.random.randint(0, 1000, 1000)]),\n",
    "        'Many Duplicates': np.random.choice(100, test_size),\n",
    "        'Normal Distribution': np.random.normal(50000, 15000, test_size).astype(int)\n",
    "    }\n",
    "    \n",
    "    gpu_alg_results = {}\n",
    "    \n",
    "    for dist_name, data in distributions.items():\n",
    "        gpu_alg_results[dist_name] = {}\n",
    "        print(f\"Distribution: {dist_name}\")\n",
    "        \n",
    "        for alg_name, alg_func in gpu_algorithms.items():\n",
    "            try:\n",
    "                avg_time = time_sort_gpu(alg_func, data, runs=3)\n",
    "                gpu_alg_results[dist_name][alg_name] = avg_time\n",
    "                print(f\"  {alg_name}: {avg_time:.6f}s\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {alg_name}: ERROR - {e}\")\n",
    "                gpu_alg_results[dist_name][alg_name] = float('inf')\n",
    "        print()\n",
    "    \n",
    "    # Visualize results\n",
    "    if gpu_alg_results:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        distributions_list = list(gpu_alg_results.keys())\n",
    "        algorithms_list = list(gpu_algorithms.keys())\n",
    "        \n",
    "        x = np.arange(len(distributions_list))\n",
    "        width = 0.25\n",
    "        \n",
    "        for i, alg in enumerate(algorithms_list):\n",
    "            times = [gpu_alg_results[dist].get(alg, float('inf')) for dist in distributions_list]\n",
    "            times = [t if t != float('inf') else 0 for t in times]  # Replace inf with 0 for plotting\n",
    "            ax.bar(x + i * width, times, width, label=alg)\n",
    "        \n",
    "        ax.set_xlabel('Data Distribution')\n",
    "        ax.set_ylabel('Time (seconds)')\n",
    "        ax.set_title('GPU Algorithm Performance by Data Distribution')\n",
    "        ax.set_xticks(x + width)\n",
    "        ax.set_xticklabels(distributions_list, rotation=45)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"GPU not available for additional testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf86cdb",
   "metadata": {},
   "source": [
    "## Conclusion and Key Findings\n",
    "\n",
    "This notebook demonstrates the power of GPU acceleration for sorting algorithms:\n",
    "\n",
    "### Key Findings:\n",
    "1. **GPU algorithms excel with large datasets** due to parallel processing capabilities\n",
    "2. **Memory transfer overhead** affects performance on small datasets\n",
    "3. **CuPy's built-in sort** typically provides the best balance of performance and reliability\n",
    "4. **Radix sort** can be extremely fast for integer data with limited range\n",
    "5. **Different data distributions** can significantly impact algorithm performance\n",
    "\n",
    "### Recommendations:\n",
    "- Use **CPU algorithms** for small datasets (< 10,000 elements)\n",
    "- Use **GPU algorithms** for large datasets (> 100,000 elements)\n",
    "- **CuPy Sort** is generally the best choice for GPU sorting\n",
    "- Consider **Radix Sort** for integer-only data\n",
    "- Always profile with your specific data characteristics\n",
    "\n",
    "### Google Colab Optimization Tips:\n",
    "1. Enable GPU runtime: Runtime → Change runtime type → GPU\n",
    "2. Monitor GPU memory usage with `!nvidia-smi`\n",
    "3. Use `cp.cuda.Device().mem_info` to check available memory\n",
    "4. Clear GPU memory between tests with `cp.get_default_memory_pool().free_all_blocks()`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
